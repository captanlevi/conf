{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastFlow.flowprintOptimal.sekigo.train import Trainer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from fastFlow.flowprintOptimal.sekigo.utils.evaluations import EarlyEvaluation\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from fastFlow.flowprintOptimal.sekigo.utils.documentor import Documenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = dict(\n",
    "    name = \"dummy\",\n",
    "    description = \"dummy\",\n",
    "    \n",
    "    common_config = dict(\n",
    "        max_timesteps = 15,\n",
    "        min_timesteps = 8\n",
    "    ),\n",
    "    \n",
    "    full_model_kwargs = dict(\n",
    "        lstm_hidden_size = 256,\n",
    "        layers= 2, lstm_input_size = 4\n",
    "    ),\n",
    "\n",
    "    early_model_kwargs = dict(\n",
    "        lstm_input_size= 4,lstm_hidden_size= 256,layers = 2                    \n",
    "    ),\n",
    "    \n",
    "    data_config = dict(\n",
    "        dataset_name = \"dummy\",\n",
    "        subsampleConfig = None,#dict(max_gap = 20, min_gap = 5),                             \n",
    "        max_flow_length = 100, # in seconds  ( each flow sample cannot excede this length)\n",
    "        test_size = .2,\n",
    "        ood_classes = [],\n",
    "        do_balance = False,\n",
    "        data_type = \"media_representation\",\n",
    "        truncate_length = 20\n",
    "\n",
    "    ),\n",
    "\n",
    "    rewarder_config = dict(\n",
    "        l = .5\n",
    "    ),\n",
    "\n",
    "    dataset_config = dict(\n",
    "        aug = [0,.2]\n",
    "    ),\n",
    "\n",
    "    memory_fillter_config = dict(\n",
    "        ood_config = dict(ood_aug = [.6,.9], ood_prob = .2),\n",
    "        min_length = 1,\n",
    "        use_balancer = False\n",
    "    ),\n",
    "    full_trainer_config = dict(\n",
    "        use_sampler = False\n",
    "    ),\n",
    "    early_trainer_config = dict(\n",
    "        use_sampler = False  # this is for giving more weight to wait samples\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Got datasets\n",
      "139950\n",
      " 1    70986\n",
      " 0    54804\n",
      "-1    14160\n",
      "Name: count, dtype: int64\n",
      " ---- 1000 metric q_loss = 0.3823424042761326\n",
      "updated best with f1 = 0.7852944926797036\n",
      " ---- 1 metric test_eval_f1 = 0.7852944926797036\n",
      " ---- 1 metric test_eval_time = 1.8503401360544218\n",
      " ---- 1 metric incorrect_ood_test = 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ConfAnalysis/fastFlow/flowprintOptimal/sekigo/train.py:45\u001b[0m, in \u001b[0;36mTrainer.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m train_dataset,test_dataset,ood_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetDatasets(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetFlows())\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mood_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mood_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ConfAnalysis/fastFlow/flowprintOptimal/sekigo/train.py:78\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_dataset, test_dataset, ood_dataset)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mSeries(labels)\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mddq_model \u001b[38;5;241m=\u001b[39m EarlyClassificationtrainer(predictor\u001b[38;5;241m=\u001b[39m predictor,train_dataset \u001b[38;5;241m=\u001b[39m train_dataset,test_dataset\u001b[38;5;241m=\u001b[39m test_dataset,memory_dataset\u001b[38;5;241m=\u001b[39m memory_dataset,\n\u001b[1;32m     75\u001b[0m                                ood_dataset\u001b[38;5;241m=\u001b[39m ood_dataset,use_sampler\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_trainer_config\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_sampler\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     76\u001b[0m                                logger\u001b[38;5;241m=\u001b[39m logger,device\u001b[38;5;241m=\u001b[39mdevice,model_replacement_steps\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mddq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.0003\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.99\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ConfAnalysis/fastFlow/flowprintOptimal/sekigo/earlyClassification/DQL/trainers.py:186\u001b[0m, in \u001b[0;36mEarlyClassificationtrainer.train\u001b[0;34m(self, epochs, batch_size, lr, lam)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m--> 186\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictor_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m         steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m            \n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m steps\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/ConfAnalysis/fastFlow/flowprintOptimal/sekigo/earlyClassification/DQL/trainers.py:122\u001b[0m, in \u001b[0;36mEarlyClassificationtrainer.trainStep\u001b[0;34m(self, steps, batch, lam, predictor_optimizer)\u001b[0m\n\u001b[1;32m    120\u001b[0m loss \u001b[38;5;241m=\u001b[39m q_loss\n\u001b[1;32m    121\u001b[0m predictor_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 122\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m predictor_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39maddMetric(metric_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m q_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218077449722977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.ddq_model.best[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentor = Documenter(train_dataset= trainer.train_dataset,test_dataset= trainer.test_dataset, ood_dataset = trainer.ood_dataset,full_model= trainer.ddq_model.best[\"model\"], early_model= trainer.ddq_model.best[\"model\"],\n",
    "                        configs= configs\n",
    "                        )\n",
    "documentor.document(name= configs[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dummy full model\n"
     ]
    }
   ],
   "source": [
    "documentor = Documenter.load(\"deployment_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = documentor.test_dataset\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = EarlyEvaluation(min_steps= 1,device= device,model= documentor.early_model).getMetrices(dataset= documentor.test_dataset,ood_dataset= documentor.ood_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13,   4,   0,   1,   0,   9],\n",
       "       [  4,  38,   3,   4,   1,   5],\n",
       "       [  0,   3,  38,   0,   0,   3],\n",
       "       [  5,   1,   3, 147,  13,  10],\n",
       "       [  0,   0,   0,  25,  24,   0],\n",
       "       [ 10,   5,   3,   1,   0,  42]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval[\"cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.727710843373494,\n",
       " 'macro_f1': 0.6690385548652649,\n",
       " 'accuracy': 0.727710843373494,\n",
       " 'cm': array([[ 13,   4,   0,   1,   0,   9],\n",
       "        [  4,  38,   3,   4,   1,   5],\n",
       "        [  0,   3,  38,   0,   0,   3],\n",
       "        [  5,   1,   3, 147,  13,  10],\n",
       "        [  0,   0,   0,  25,  24,   0],\n",
       "        [ 10,   5,   3,   1,   0,  42]]),\n",
       " 'per_class_f1': array([0.44067797, 0.71698113, 0.83516484, 0.82352941, 0.55172414,\n",
       "        0.64615385]),\n",
       " 'time': 9.602409638554217,\n",
       " 'time_std': 5.129033256418724,\n",
       " 'incorrect_ood': 0.002403846153846154}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Twitter': 0, 'LinkedIn': 1, 'TikTok': 2, 'Facebook': 3, 'Instagram': 4, 'Reddit': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.48148148, 0.69090909, 0.86363636, 0.82122905, 0.48979592,\n",
       "       0.68852459])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = eval[\"cm\"]\n",
    "print(documentor.test_dataset.label_to_index)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.727710843373494,\n",
       " 'macro_f1': 0.6690385548652649,\n",
       " 'accuracy': 0.727710843373494,\n",
       " 'cm': array([[ 13,   4,   0,   1,   0,   9],\n",
       "        [  4,  38,   3,   4,   1,   5],\n",
       "        [  0,   3,  38,   0,   0,   3],\n",
       "        [  5,   1,   3, 147,  13,  10],\n",
       "        [  0,   0,   0,  25,  24,   0],\n",
       "        [ 10,   5,   3,   1,   0,  42]]),\n",
       " 'per_class_f1': array([0.44067797, 0.71698113, 0.83516484, 0.82352941, 0.55172414,\n",
       "        0.64615385]),\n",
       " 'time': 9.602409638554217,\n",
       " 'time_std': 5.129033256418724,\n",
       " 'incorrect_ood': 0.002403846153846154}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,packet_taken,labels = EarlyEvaluation(min_steps= 1,device= device,model= documentor.early_model).predictOnDataset(dataset= documentor.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = documentor.test_dataset.label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter 0.0\n",
      "LinkedIn 0.0\n",
      "TikTok 0.0\n",
      "Facebook 0.005555555555555556\n",
      "Instagram 0.0\n",
      "Reddit 0.0\n"
     ]
    }
   ],
   "source": [
    "for name,index in label_to_index.items():\n",
    "    fpr = ((pred == -1)&(labels == index)).sum()/((labels == index).sum())\n",
    "    print(name, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter 9.74074074074074 4.427126754810055\n",
      "LinkedIn 10.527272727272727 5.263440096827603\n",
      "TikTok 6.318181818181818 3.521187346702602\n",
      "Facebook 9.905555555555555 5.23205634337465\n",
      "Instagram 11.16326530612245 5.5745300480079285\n",
      "Reddit 9.098360655737705 4.622485734075414\n"
     ]
    }
   ],
   "source": [
    "for name,index in label_to_index.items():\n",
    "    t_label = packet_taken[labels == index]\n",
    "    print(name, t_label.mean(), t_label.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flowprintOptimal.sekigo.flowUtils.commons import dropPacketFromPacketRep, getTimeStampsFromIAT\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = documentor.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,packet_taken,_ = EarlyEvaluation(min_steps= 1,device= device,model= documentor.early_model).predictOnDataset(dataset= dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IATs = [p.inter_arrival_times for p in dataset.flows]\n",
    "timestamps = Parallel(n_jobs=10)(delayed(getTimeStampsFromIAT)(iat) for iat in IATs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convetPacketsTakenToTimeTaken(timestamps,packets_taken):\n",
    "    time_taken = []\n",
    "    for i in range(len(packets_taken)):\n",
    "        time_taken.append((timestamps[i][packets_taken[i] - 1] - timestamps[i][0]).total_seconds() )\n",
    "    \n",
    "    return np.array(time_taken)\n",
    "\n",
    "\n",
    "time_taken = convetPacketsTakenToTimeTaken(timestamps= timestamps, packets_taken= packet_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4023385432692308, 3.243947830354812)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_taken.mean(), time_taken.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter 2.948781851851852 10.342726184024174\n",
      "LinkedIn 0.27158380000000004 1.6295024286113442\n",
      "TikTok 0.13042127272727272 0.18921756672933696\n",
      "Facebook 0.06348779444444445 0.28307474590012244\n",
      "Instagram 0.29100461224489793 1.3902223097047497\n",
      "Reddit 0.6785745901639345 4.1041018335218915\n"
     ]
    }
   ],
   "source": [
    "for name,index in label_to_index.items():\n",
    "    t_label = time_taken[labels == index]\n",
    "    print(name, t_label.mean(), t_label.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
